# DetecÃ§Ã£o de Fraudes em TransaÃ§Ãµes â€” Machine Learning (PaySim/Fraude.csv)

Projeto de **classificaÃ§Ã£o binÃ¡ria** para detectar **fraudes em transaÃ§Ãµes financeiras** a partir de uma base de dados de comÃ©rcio eletrÃ´nico (`Fraude.csv`).  
O pipeline cobre: **carregamento**, **prÃ©-processamento**, **tratamento de desbalanceamento**, **treinamento de mÃºltiplos modelos**, **avaliaÃ§Ã£o** e **ensemble**.

---

## âœ¨ Objetivo

Construir e comparar modelos de Machine Learning para prever a coluna **`isFraud`**:

- `0` â†’ transaÃ§Ã£o legÃ­tima  
- `1` â†’ transaÃ§Ã£o fraudulenta  

Como o problema Ã© **altamente desbalanceado**, o foco nÃ£o Ã© â€œacurÃ¡ciaâ€, e sim mÃ©tricas como **Recall, Precision e F1-score** para a classe minoritÃ¡ria (fraude).

---

## ğŸ§¾ Dataset

O arquivo utilizado no notebook Ã©:

- `Fraude.csv`

Estrutura inicial (exemplo de colunas):
- `step`, `type`, `amount`, `nameOrig`, `oldbalanceOrg`, `newbalanceOrig`,
- `nameDest`, `oldbalanceDest`, `newbalanceDest`,
- `isFraud`, `isFlaggedFraud`

> ObservaÃ§Ã£o: o dataset Ã© grande (milhÃµes de linhas). Rodar tudo pode exigir bastante RAM.

---

## ğŸ§  Pipeline (o que o notebook faz)

### 1) Carregamento
- Monta o Google Drive no Colab
- Carrega o CSV com `pandas`

### 2) ValidaÃ§Ã£o de integridade
- Verifica **duplicatas**
- Verifica **valores faltantes (NaN)**

### 3) Encoding de variÃ¡veis categÃ³ricas
- Aplica `LabelEncoder` em colunas do tipo `object` (ex.: `type`, `nameOrig`, `nameDest`)

### 4) AnÃ¡lise exploratÃ³ria (rÃ¡pida)
- Mostra **desbalanceamento** da variÃ¡vel alvo `isFraud`
- Plota **matriz de correlaÃ§Ã£o** com heatmap

### 5) SeleÃ§Ã£o/remoÃ§Ã£o de colunas
Removeu:
- `nameOrig`, `nameDest` (sensÃ­veis / identificadores)
- `isFlaggedFraud` (potencial vazamento/feature â€œentregandoâ€ o alvo)
- `newbalanceOrig`, `newbalanceDest` (reduÃ§Ã£o de dimensionalidade)

Features finais:
- `step`, `type`, `amount`, `oldbalanceOrg`, `oldbalanceDest`
- alvo: `isFraud`

> ApÃ³s remover colunas, podem surgir â€œduplicatasâ€ por perda de distinÃ§Ã£o; o notebook remove essas linhas duplicadas.

### 6) NormalizaÃ§Ã£o
- Aplica `MinMaxScaler` para colocar as features na escala `[0, 1]`

### 7) Split treino/teste
- Divide em `80/20` com `train_test_split`

### 8) Balanceamento (undersampling)
- Usa `RandomUnderSampler` para equalizar as classes no treino

### 9) Treinamento e avaliaÃ§Ã£o
Modelos testados:
- Decision Tree
- Random Forest
- Extra Trees
- Passive Aggressive
- XGBoost
- SVM
- KNN

AvaliaÃ§Ã£o:
- **Curva ROC + AUC**
- **AcurÃ¡cia**
- **Especificidade**
- **Classification Report**
- **Matriz de confusÃ£o** (valores + %)

### 10) Ensemble heterogÃªneo
- `VotingClassifier` (hard voting) com os modelos acima
- Avalia as mesmas mÃ©tricas e plota matriz de confusÃ£o

---

## âœ… Resultados (resumo)

O notebook indica o **XGBoost** como modelo escolhido, por ter bom desempenho na classe minoritÃ¡ria (`isFraud=1`), principalmente em **Recall** e **F1-score**.

> Importante: em bases desbalanceadas, **acurÃ¡cia** pode ser alta mesmo com desempenho ruim para fraudes. O ideal Ã© focar em **Recall/Precision/F1 da classe 1** e calibrar o limiar de decisÃ£o quando necessÃ¡rio.

---

## ğŸ”§ Como executar

### OpÃ§Ã£o A) Google Colab (recomendado)
1. Abra o notebook no Colab
2. Monte o Drive quando solicitado
3. Ajuste o caminho do dataset:
   ```python
   dataset = "/content/drive/MyDrive/Colab Notebooks/ComeÌrcio EletroÌ‚nico/Fraude.csv"
